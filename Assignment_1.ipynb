{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZNSDOBJcBm"
      },
      "source": [
        "# Assignment I: PyTorch & Language Models\n",
        "\n",
        "In this first assignment we will work with PyTorch and Open AI's early open source model GPT2 to develop a base understanding and intuition of how language models work and how they are trained. We will also look at a specific simple task, Sentiment Classification, and see in two ways how we can use language models for this problem.\n",
        "\n",
        "The structure of the Assignment is as follows:\n",
        "\n",
        "1. **PyTorch Basics: Common Operations**\n",
        "\n",
        "   We first want to familiarize ourselves more with some basics of PyTorch. We will perform a few operations and test some of the functions we will do later.\n",
        "\n",
        "2. **Basic GPT-2 Usage**\n",
        "\n",
        "   Next, we will download GPT-2 from Hugging Face. The model is a smaller and older Decoder model released in 2018. We will do a few exercises that help us to understand the models.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Oaj-qCl1ha"
      },
      "source": [
        "For reference, please consider the Lecture material for weeks 2 & 3 as well as the two Special Session notebooks:\n",
        "\n",
        "* Intro to PyTorch I (Basics)\n",
        "* Intro to PyTorch II (Hugging Face & Language Models)\n",
        "* Lesson Notebook for Week 2\n",
        "\n",
        "\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "\n",
        "* Before submitting, please run this entire notebook end-to-end using Colab Pro or the free Colab version. Then download the exectuted notebook and submit that one.  This is **very important** because we set a random seed which allows the results of runs to be more deteministic and enables more rapid grading.\n",
        "  \n",
        "* Questions are always indicated as **QUESTION**, so you can search for this string to make sure you answered all of the questions. You are expected to fill out, run, and submit this notebook. Please do not remove the output from your notebooks when you submit them as we'll look at the output as well as your code for grading purposes.\n",
        "\n",
        "* \\### YOUR CODE HERE indicates that you are supposed to write code.\n",
        "* \\### YOUR ANSWER HERE indicates that you are supposed to write your answer. Please put your answer as either a string or a raw number -- no executable code, for example \"3,15,24\" or 0.123.\n",
        "\n",
        "**AUTOGRADER:**\n",
        "\n",
        "- In each code block, do NOT delete the ### comment at the top of a cell (it's needed for the auto-grading!)\n",
        "  - Full autograder tests for the first 3 questions are on gradescope.\n",
        "  - You may upload and run the autograder as many times as needed in your time window to get full points for those 3 questions.\n",
        "  - The assignment needs to be named Assignment_1.ipynb to be graded from the autograder!\n",
        "  - The examples given are samples of how we will test/grade your code.\n",
        "    - Please ensure your code outputs the exact same information / format!\n",
        "    - Each autograder test tells you what input it is using\n",
        "  - Once complete, the autograder will show each test, if that test is passed or failed, and your total score\n",
        "  - The autograder fails for a couple of reasons:\n",
        "    - Your code crashes with that input (for example: `Test Failed: string index out of range`)\n",
        "    - Your code output does not match the 'correct' output (for example: `Test Failed: '1 2 3 2 1' != '1 4 6 4 1'`)\n",
        "- Please format your input and output strings to be user friendly\n",
        "- Adding comments in your code is strongly suggested but won't be graded.\n",
        "- If you are stuck on a problem or do not understand a question - please come to office hours or ask questions (please don't post your code though). If it is a coding problem send a private email to your instructor.\n",
        "- We also have TAs for extra help and 1 on 1 sessions!\n",
        "- You may use any libraries from the Python Standard Library for this assignment: https://docs.python.org/3/library/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtkgx-8fl1ha"
      },
      "source": [
        "## 0. Setup\n",
        "\n",
        "Let us first install a few required packages. (You may want to comment this out in case you use a local environment that already has the suitable packages installed.)\n",
        "\n",
        "Note our use of `%%capture` in the cell below absorbs all of the output when the model(s) are loading.  You can comment it out if you want to see that output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuN074G-JK_T"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#!pip install torch.     # commented because it is pre-installed in Colab\n",
        "!pip install torchtext\n",
        "!pip install transformers\n",
        "#!pip install numpy      # commented because it is pre-installed in Colab\n",
        "!pip install portalocker\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Lv5JrRl1hb"
      },
      "source": [
        "Next, we will import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgVjAiytl1hb"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, GPT2Model, GPT2ForSequenceClassification, GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZmkkCXxuf0o",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Let's make sure we will later put data and models on the proper device:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9piY_5XnuVa9"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZt63SBLl1hc"
      },
      "source": [
        "This should say 'cpu' if using a CPU, or 'cuda', if a GPU is used (or 'mps' per the comment).\n",
        "\n",
        "Now let's get started!\n",
        "\n",
        "## 1. PyTorch Basics: Common Operations\n",
        "\n",
        "Let's get started with some simple operations. For reference you should use the PyTorch documentation at https://pytorch.org/docs/stable/index.html .\n",
        "\n",
        "Review the PyTorch Intro I notebook. Your goal is to create a simple neural net with two connected layers that takes a (random) input that we will create and 'classifies' imagining a 3-class prediction problem. (We will not train the model, so the purpose is simply to test dimensions, expressions, etc., but not real values. We do however want you to execute the cells consecutively in the proper order so that we can compare the final (randomly generated) outcomes. They should always be the same given the manual seed that we set.)  \n",
        "\n",
        "We start with setting the seed which insures that the answers are more deteministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf6nwBQsl1hc",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMvs5BWal1hd"
      },
      "source": [
        "### 1.a Tensor Manipulation\n",
        "\n",
        "Now consider 1.a of the PyTorch I notebook and generate a random input dataset that mimics 4 examples with 6 features each. Consider using  torch.rand()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2XSpoPil1hd"
      },
      "outputs": [],
      "source": [
        "input_dim = 6\n",
        "n_examples = 4\n",
        "n_classes = 3\n",
        "#call your generated input tensor 'input_data'\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "input_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7YBqgxnl1hd"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.a. What is the value of the input_data[0,0]? (Make sure you just re-ran the manual seed.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOHV3ARmtFht"
      },
      "outputs": [],
      "source": [
        "### Q1-a Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emZnD87dl1hd"
      },
      "source": [
        "Let's now do a few simple exercises. Using torch.argmax (https://pytorch.org/docs/stable/generated/torch.argmax.html), find the index of the maximum element for each row and each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW9srHfCl1hd"
      },
      "outputs": [],
      "source": [
        "# call your indices row_ind_max_arg and col_ind_max_arg\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "### END YOUR CODE\n",
        "print('Index of argmax for each row', row_ind_max_arg)\n",
        "print('Index of argmax for each column', col_ind_max_arg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf12HlYAl1hd"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.b. What are the indices of the elements with the largest value in each row? Copy the list of indices to the answer cell and represent them as a list e.g. [55, 77, 99, 11].   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdnZ6mjW-Oyt"
      },
      "outputs": [],
      "source": [
        "### Q1-b Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BveXAeJW-JPH"
      },
      "source": [
        "1.c. What are the indices of the elements with the largest value in each column? Again, copy the list of indices to the answer cell and represent them as a list e.g. [55, 77, 99, 11]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcVPaMj8-ByP"
      },
      "outputs": [],
      "source": [
        "### Q1-c Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6oejR97l1hd"
      },
      "source": [
        "You can get the values of a tensor just like you can for numpy. For example, the values for the last column (i.e., fixed second dimension) can be obtained through:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sILEH-Ycl1hd"
      },
      "outputs": [],
      "source": [
        "print(input_data[:, -1])\n",
        "print(input_data[:, 5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfNjSiv_l1hd"
      },
      "source": [
        "Similarly, get the values of the last row (first index 'last', second index unconstrained):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3IgW_vhl1hd"
      },
      "outputs": [],
      "source": [
        "# call your values for the last row last_row\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Values of last row: ', last_row)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alVM9425l1hd"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.d. Copy the tensor of the last row into the answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftuAPla9-mQo"
      },
      "outputs": [],
      "source": [
        "### Q1-d Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkRmzM6Ll1hd"
      },
      "source": [
        "Next, reshape input_data into a 2x12 tensor using \\<tensor>.reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbC8tIzql1he"
      },
      "outputs": [],
      "source": [
        "# call your reshaped tensor reshaped_input_data\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Reshaped data shape: ', reshaped_input_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI2lh_t2l1he"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.e. Write the shape of the reshaped tensor as a tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBDEYR52-x4v"
      },
      "outputs": [],
      "source": [
        "### Q1-e Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrpCxcLSl1he"
      },
      "source": [
        "### b. The Simple Classification Network\n",
        "\n",
        "Now construct the network. Fill in your code for the __init__ and forward methods. Again, we want to have two hidden layers (dims: hidden_dim_1, hidden_dim_2) with relu activation functions, and output layer of dimension n_classes (and softmax activation function). The model should return both the probabilities (probs) and the logits (logits), as you can tell from the return statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZw1UUqpl1he"
      },
      "outputs": [],
      "source": [
        "class SimpleClassificationNertwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, n_classes):\n",
        "        super().__init__()\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "        return probs, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXhIyuu4l1he"
      },
      "outputs": [],
      "source": [
        "mySimpleClassificationNertwork = SimpleClassificationNertwork(input_dim=input_dim,\n",
        "                                                              hidden_dim_1=7,\n",
        "                                                              hidden_dim_2=10,\n",
        "                                                              n_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAEmtIWel1he"
      },
      "outputs": [],
      "source": [
        "probs,logits = mySimpleClassificationNertwork(input_data)\n",
        "\n",
        "print('Probabilities:\\n\\t', probs)\n",
        "print('\\nLogits:\\n\\t', logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Ur9b8Al1he"
      },
      "source": [
        "**NOTE: Once everything works please rerun the cells starting with setting the manual seed up to this cell to make sure that the numbers (if everything is correct) can be compared to the solutions!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXeztSdkl1he"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.f. Copy the tensor for the probabilities into the answer file.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEhclh8Z-7wk"
      },
      "outputs": [],
      "source": [
        "### Q1-f Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2_dOGa-747"
      },
      "source": [
        "1.g. Copy the tensor for the logits into the answers file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhTwADop-8Bo"
      },
      "outputs": [],
      "source": [
        "### Q1-g Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiL8z3tNl1he"
      },
      "source": [
        "Great. Next do a calculation that *manually* verifies that the Softmax calculation is correct. Specifically, please recalculate the probability of the first class of the first example (use np.exp()... And if you don't want to use the numbers above, but the expressions probs and logits in a suitable way, use \\<tensor\\>.detach().numpy() to convert to numpy!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntAbVVg1l1hf"
      },
      "outputs": [],
      "source": [
        "# call your probability of the first class for the first example p_1_1\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "p_1_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5j_aT9fl1hf"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.h. Copy the value of `p_1_1` into the answers file. (Note that the first class has index 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5e_y9Jl_eC3"
      },
      "outputs": [],
      "source": [
        "### Q1-h Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZDCGjcol1hf"
      },
      "source": [
        "Great. Now imagine that the correct classes are 0, 1, 2, 0 for the four examples. What is the average loss? For that we will first define the loss function and then calculate the loss. Note that the input to the CrossEntropyLoss() function are i) the un-normalized logits, and ii) either the class probabilities or the actual classes (better in this case as each example belongs to a class)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IErI7-zl1hf"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "loss = loss_fn(logits, torch.tensor([0, 1, 2, 0]))\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSqViTkFl1hf"
      },
      "source": [
        "Now verify that this loss agrees with the manual calculation. Recall from Week 2 that\n",
        "\n",
        "$$ CE \\rightarrow -\\frac{1}{N}\\sum_k \\log(q^k_{{correct \\ class}}) $$\n",
        "\n",
        "where k refers to the example, N is the number of examples, and\n",
        "\n",
        "$$q_{{correct \\ class}}$$\n",
        "\n",
        "is the model probability for the correct class for a given example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvjQBsDPl1hf"
      },
      "outputs": [],
      "source": [
        "# call your manual loss calculation manual_loss\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "manual_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8fQeSmEl1hf"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.i. Write out the complete Cross-Entropy loss calculation as a single mathematical expression, substituting the values (the floating point numbers) you arrived at in your earlier work on this assignment.  Your answer should be a single line showing the entire calculation with all necessary values inserted.\n",
        "\n",
        "\n",
        "Note: Do not perform any calculations or simplify the expression. Simply write out the formula with the appropriate numeric values inserted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQSzigUx_qCQ"
      },
      "outputs": [],
      "source": [
        "### Q1-i Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owiME_Khl1hf"
      },
      "source": [
        "Great. Now we are ready to move to Language Models.\n",
        "\n",
        "## 2. Basic GPT-2 Usage\n",
        "\n",
        "We are now downloading GPT-2 from Hugging Face. We will get the Tokenizer and the model. We will make sure that it is on the proper device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysYdbU-2l1hr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "gpt_2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "#gpt_2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJarqs_kl1hr"
      },
      "source": [
        "We can simply apply the tokenizer to a sentence to see how words are converted into word indices (which will be model inputs and, as first order of business for the model, be converted to word vectors). (The tokenizer is model-specific and various tokenizers have some special considerations/quirks. You should always take a look at how a specific tokenizer works. Consult the Hugging Face docs and try some examples.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXbiGPo0l1hr"
      },
      "outputs": [],
      "source": [
        "gpt_2_tokenizer(\"What a nice day\", return_tensors='pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgcEzG4Rl1hr"
      },
      "source": [
        "Note the difference between encodings of a word when the word is at the very beginning of a sentence vs a word that occurs later in the sentence. (The attention masks become important if you have examples of varying length and padding tokens are used to make sure that model inputs are of the same length. The return_tensors option is used to get the tokenization into a format that is suitable for model input, if desired. Following, we will omit the return_tensors option as we don't need it here.)\n",
        "\n",
        "Below, consider the embedding for 'I' in the three tokenizations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk3irKCgl1hr"
      },
      "outputs": [],
      "source": [
        "print(gpt_2_tokenizer(\"I am\")['input_ids'])\n",
        "print(gpt_2_tokenizer(\"am I\")['input_ids'])\n",
        "print(gpt_2_tokenizer(\" I\")['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldDOXOb_l1hr"
      },
      "source": [
        "Decoding  (e.g. turn your input_id back into the coresponding string) is done with \\<tokenizer>.decode():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtoWHMRKl1hr"
      },
      "outputs": [],
      "source": [
        "gpt_2_tokenizer.decode([314])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6VIV_Qxl1hr"
      },
      "source": [
        "Please tokenize the longest word that Shakespeare used: 'honorificabilitudinitatibus' (when not at the beginning of a sentence), and find the first token (not the id, but the corresponding token string):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qto1E5mql1hr"
      },
      "outputs": [],
      "source": [
        "# Name your tokenization tokenized_long_word, the index of the first token first_index, and the first token first_token\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Tokenized long word: ', tokenized_long_word)\n",
        "print('Length of tokenized long word: ', len(tokenized_long_word))\n",
        "print('First index: ', first_index)\n",
        "print('First token: ', first_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94iz3CUjl1hr"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "2.a. Into how many tokens is the word honorificabilitudinitatibus split when not in the beginning of the sentence? (You can either create a sentence with this word where it is not in the beginning, or you need to make sure that there is a space in front of the word.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsrKyxW-_6ja"
      },
      "outputs": [],
      "source": [
        "### Q2-a Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlTS1Cbz_6qe"
      },
      "source": [
        "2.b. What is the first token of the tokenization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI2VTfXg_6wr"
      },
      "outputs": [],
      "source": [
        "### Q2-b Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_dG50rFl1hs"
      },
      "source": [
        "Now redo the same, but imagine the word 'honorificabilitudinitatibus' at the very start of a sentence/doc (never mind the capitalization) as in\n",
        "'honorificabilitudinitatibus is a state I am in'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttvKEXbGl1hs"
      },
      "outputs": [],
      "source": [
        "# Now name your tokenization beg_tokenized_long_word, the index of the first token beg_first_index, and the first token beg_first_token\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Tokenized long word: ', beg_tokenized_long_word)\n",
        "print('First index: ', beg_first_index)\n",
        "print('First token string: ', beg_first_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQHssnbwl1hs"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "2.c. Into how many tokens is the word honorificabilitudinitatibus now be split (when **in** the beginning of the sentence)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpNg0TOxAMHE"
      },
      "outputs": [],
      "source": [
        "### Q2-c Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Pd-V7UAMNR"
      },
      "source": [
        "2.d. What is now the first token string of the tokenization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlkYBZUdAMVL"
      },
      "outputs": [],
      "source": [
        "### Q2-d Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjJQGYNOl1hs"
      },
      "source": [
        "Now apply the gpt2_model to a sentence in order to predict the most likely next word after 'The movement started in Italy. From there it went to France and Switzerland.  Soon it spread throughout'. You may want to consult the PyTorch Introduction II Notebook and the Week 2 lesson notebook.\n",
        "\n",
        "Please get i) the shape of the output, ii) the values of the logits of the last token,  iii) the index of the  token with largest logit, and iv) the token that belongs to it. Same for the token with the second most largest logit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpFr-U49l1hs"
      },
      "outputs": [],
      "source": [
        "text = \"The movement started in Italy. From there it went to France and Switzerland.  Soon it spread throughout\"\n",
        "input = gpt_2_tokenizer(text, return_tensors='pt')\n",
        "\n",
        "gpt_out = gpt2_model(**input)\n",
        "\n",
        "# Please call your model output shape, output_shape, the logits for the last position last_logits,\n",
        "# the index for the token with the largest last_logit value max_logit_index, and the corresponding token max_logit_token.\n",
        "# Name the corresponding values for the second largest logit second_logit_index, second_logit_token, and second_logit.\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Output shape: ', output_shape)\n",
        "print('Logits of output for last token: ', output_logits)\n",
        "print('Index of token with largest logit: ', max_logit_index)\n",
        "print('Token with largest logit: ', max_logit_token)\n",
        "print('Logit of token with largest logit: ', max_logit)\n",
        "print('Index of token with second largest logit: ', second_logit_index)\n",
        "print('Token with second largest logit: ', second_logit_token)\n",
        "print('Logit of token with second largest logit: ', second_logit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVqWVn7Tl1hs"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "2.e. What is the shape of the output?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA6R6lIHAyod"
      },
      "outputs": [],
      "source": [
        "### Q2-e Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqCZ4hEKAyxm"
      },
      "source": [
        "2.f. What do the three numbers shape refer to?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcuNcrUEAy4Y"
      },
      "outputs": [],
      "source": [
        "### Q2-f Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoU6I9UFAy_j"
      },
      "source": [
        "2.g. What is the index of the word with the largest logit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4VDOMTCAzF-"
      },
      "outputs": [],
      "source": [
        "### Q2-g Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMEv0UNeAzN9"
      },
      "source": [
        "2.h. What is the token string associated with the largest logit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POtmJXPeAzVE"
      },
      "outputs": [],
      "source": [
        "### Q2-h Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwK9cDX7Azfl"
      },
      "source": [
        "2.i. What is the second most likely token id?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krZmitkoAzmQ"
      },
      "outputs": [],
      "source": [
        "### Q2-i Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvpI-4QQAzuD"
      },
      "source": [
        "2.j. What is the second most likely word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJzzv-osA_3Y"
      },
      "outputs": [],
      "source": [
        "### Q2-j Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC3up6pwl1hs"
      },
      "source": [
        "Now we will translate the logits into relative token probabilities depending on the chosen temperature. Use numpy or pytorch calculations. (But remember to use .detach() etc if you want to use numpy.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqVBaCEtl1hs"
      },
      "outputs": [],
      "source": [
        "T_1 = 1.\n",
        "T_2 = 10.\n",
        "T_3 = 0.1\n",
        "\n",
        "# Please call your relative probabilities between the most likely token and the second most likely token p_t1, p_t2, p_t3, depending\n",
        "# on the temperature\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "print('Logit ratio for T1: ', p_t1)\n",
        "print('Logit ratio for T2: ', p_t2)\n",
        "print('Logit ratio for T3: ', p_t3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap07xAI-l1hs"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "2.k. What is the ratio of probabilities between the most likely token and the second most likely token if T=1?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7N1opQpBlXr"
      },
      "outputs": [],
      "source": [
        "### Q2-k Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6SIoGPfBlf1"
      },
      "source": [
        "2.l. What is the ratio of probabilities between the most likely token and the second most likely token if T=10?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXGeFlEeBlnO"
      },
      "outputs": [],
      "source": [
        "### Q2-l Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ1B2JuWBlvF"
      },
      "source": [
        "2.m. What is the ratio of probabilities between the most likely token and the second most likely token if T=0.1? (Hint: to avoid a NaN you may want to use a simple mathematical identity to deal with the low temperature: $e^a/e^b = e^{(a-b)}$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysP0VJtyBl7n"
      },
      "outputs": [],
      "source": [
        "### Q2-m Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLhK3eKfl1hs"
      },
      "source": [
        "And that is it! Congratulations!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}