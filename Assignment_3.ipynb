{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZNSDOBJcBm"
      },
      "source": [
        "# Assignment III: Fine-Tuning of Language Models with QLoRA\n",
        "\n",
        "In this third assignment we will continue to work with PyTorch and Open AI's early Open Source Model GPT2 to develop a deeper understanding and intuition of how language models are fine-tuned with parameter efficient fine tuning (PEFT) techniques. We will continue to look at a specific simple task, Sentiment Classification, and see how we can fine tune two different models to improve performance.\n",
        "\n",
        "The structure of the Assignment is as follows:\n",
        "\n",
        "1. **Fine-tuning of [GPT2 large](https://huggingface.co/openai-community/gpt2-large) with a sentiment classification dataset**  \n",
        "\n",
        "   Here we will explore how we can combine Low Rank Adaptation (LoRA) with Quantization to fine tune a larger model.  We'll leverage the libaries from [Hugging Face](https://huggingface.co/docs/transformers/index) to use their AutoModel and AutoTokenizer classes as well as their Trainer class to fine tune a model to do sentiment classification. We'll experiment with some of the hyperparameters that affect LoRA performance to see what makes a positive or negative contribution.\n",
        "   We will learn that the Huggingface infrastructure allows us to easily fine tune much larger models than we could normally fit on our compute resources.\n",
        "\n",
        "2. **Fine-tuning of Gemma model for Sentiment Analysis**  \n",
        "   We will then use a larger more recent model -- [Gemma 2](https://huggingface.co/google/gemma-2b) from Google -- to illustrate the benefits of an increase in the number of parameters and how it affects the performance of the model.  This model doubles the number or parameters but has also undergone a better pre-training regime and we would expect that to be reflected in the performance of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0IwczMZFtrF"
      },
      "source": [
        "For reference, please consider the Lecture material for weeks 2 - 5 as well as the two Special Session notebooks:\n",
        "\n",
        "* Intro to PyTorch I (Basics)\n",
        "* Intro to PyTorch II (Huggingface & Language Models)\n",
        "* All lesson material and notebooks for Unit 5\n",
        "\n",
        "\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "\n",
        "* This notebook needs to be run using a GPU. If you use Google Colab, a T4 chip is the recommendation.\n",
        "  \n",
        "* Questions are always indicated as **QUESTION:**, so you can search for this string to make sure you answered all of the questions. You are expected to fill out, run, and submit this notebook, as well as to answer the questions in the answers cells as you did in a1. Please do not remove the output from your notebooks when you submit them as we'll look at the output as well as your code for grading purposes.\n",
        "\n",
        "* \\### YOUR CODE HERE indicates that you are supposed to write code. All the way up to \\### END YOUR CODE     \n",
        "\n",
        "* **Important!!:** When you are done please re-run your notebook from beginning to end to that all of the seeds apply! This is very important!\n",
        "\n",
        "**AUTOGRADER:**\n",
        "\n",
        "- In each code block, do NOT delete the ### comment at the top of a cell (it's needed for the Gradescope grading!)\n",
        "  - No autograder tests and results on this assignment.\n",
        "  - You will get the full 42 points from the human graders for this assignment.\n",
        "  - You may upload as many times as needed in your time window to get full points\n",
        "  - The assignment needs to be named Assignment_3.ipynb to be graded from the autograder!\n",
        "  - The examples given are samples of how we will test/grade your code.\n",
        "    - Please ensure your code outputs the exact same information / format!\n",
        "    - In addition to the given example, the autograder will test other examples\n",
        "- Please format your input and output strings to be user friendly\n",
        "- Adding comments in your code is strongly suggested but won't be graded.\n",
        "- If you are stuck on a problem or do not understand a question - please come to office hours or ask questions (please don't post your code though). If it is a coding problem send a private email to your instructor.\n",
        "- We also have a number of TA tutors for extra help and 1 on 1 sessions!\n",
        "- You may use any libraries from the Python Standard Library for this assignment: https://docs.python.org/3/library/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peRi8BBqFtrF"
      },
      "source": [
        "## 0. Environment Setup\n",
        "\n",
        "Let us first install a few required packages. (You may want to comment this out in case you use a local environment that already has the suitable packages installed.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install datasets==2.21.0\n",
        "!pip install transformers\n",
        "!pip install accelerate -U            # Quantization, Distribution\n",
        "!pip install -q peft                  # LoRA\n",
        "!pip install -q evaluate\n",
        "!pip install bitsandbytes             # QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "UNcBwzfVsKyV",
        "outputId": "f0113743-3d8d-4f8b-e7fb-401c08e51eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/iri5ssp2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b65bdc2b410>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "from peft import LoraConfig, TaskType, PeftModel, get_peft_model\n",
        "from peft import load_peft_weights, set_peft_model_state_dict\n",
        "from peft import PromptEncoderConfig, prepare_model_for_kbit_training\n",
        "\n",
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1KcjhDHtwY8"
      },
      "source": [
        "Some useful definitions and functions we'll use (see Text Classification notebook):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7OlSoLxdtu6j"
      },
      "outputs": [],
      "source": [
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    if sentence2_key is None:\n",
        "        return tokenizer(examples[sentence1_key], truncation=True)\n",
        "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def show_currently_allocated_gpu_mem():\n",
        "  torch.cuda.empty_cache()\n",
        "  mem = torch.cuda.memory_allocated()\n",
        "  print(f\"Current GPU memory allocation (GB): {mem/1024**3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "## 1. Data Setup\n",
        "\n",
        "We use the [GLUE dataset](https://gluebenchmark.com/), one of the original NLP \"benchmarks\", loading the data for the Stanford Sentiment Treebank task. We will also define the tokenizer for our first model (they all use the GPT2 tokenizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "outputs": [],
      "source": [
        "task = actual_task = \"sst2\"\n",
        "\n",
        "base_model_name = \"gpt2-large\"  # GPT2\n",
        "\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kvyeJEq7xmFr"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_AY1ATSIrIq",
        "outputId": "b2ea7880-fdaf-4379-f70e-76a5d3c29888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-2142620635.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('glue', actual_task, trust_remote_code=True)\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"glue\", actual_task, trust_remote_code=True)\n",
        "metric = load_metric('glue', actual_task, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3EtYfeHIrIz"
      },
      "source": [
        "To access an actual record, you need to select a split first, then give an index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5GqPC4D_L3Z",
        "outputId": "3704a29d-1340-4841-bcc9-7b3f9ce7d629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Pkgdai0kwN"
      },
      "source": [
        "Let's look at one record in the train split they provide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HrpprwIrIz",
        "outputId": "b3f0be7e-564e-415d-9a11-623a5f30901d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'that loves its characters and communicates something rather beautiful about human nature ',\n",
              " 'label': 1,\n",
              " 'idx': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset[\"train\"][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS9Xwkf-7ZdY"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.a. How many records in the train split of the sst dataset we're using?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC6uSXnv7ZdY"
      },
      "outputs": [],
      "source": [
        "### Q1-a Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "67349\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEhaXKkm7djs"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.b. How many records are in the test split of the sst dataset we're using?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w1uEw567djt"
      },
      "outputs": [],
      "source": [
        "### Q1-b Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "1821\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUmphG3IrI3"
      },
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "i3j8APAoIrI3",
        "outputId": "00f505e1-9967-4275-ab27-5da2d3c0c1b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exactly what it wants to be</td>\n",
              "      <td>positive</td>\n",
              "      <td>35362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a low-budget affair , tadpole was shot on digital video ,</td>\n",
              "      <td>negative</td>\n",
              "      <td>23615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>an almost sure-fire prescription</td>\n",
              "      <td>positive</td>\n",
              "      <td>23113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>satan is throwing up his hands in surrender , is firing his r&amp;d people , and has decided he will just screen the master of disguise 24/7 .</td>\n",
              "      <td>negative</td>\n",
              "      <td>2621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>as it is interminable</td>\n",
              "      <td>negative</td>\n",
              "      <td>16206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a fun family movie that 's suitable for all ages -- a movie that will make you laugh</td>\n",
              "      <td>positive</td>\n",
              "      <td>35973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>illuminates what it means sometimes to be inside looking out , and at other times outside looking in .</td>\n",
              "      <td>positive</td>\n",
              "      <td>6096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>worst cinematic tragedies</td>\n",
              "      <td>negative</td>\n",
              "      <td>9012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cutesy reliance</td>\n",
              "      <td>negative</td>\n",
              "      <td>20846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>never inspired</td>\n",
              "      <td>negative</td>\n",
              "      <td>33717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAWdqcUBIrJC"
      },
      "source": [
        "You can call the `compute` method associated with the glue benchmark, pass your predictions and labels directly and it will return a dictionary with the metric(s) value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XN1Rq0aIrJC",
        "outputId": "9f14b90e-c37e-4986-cc5e-3b31ed3f29f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.484375}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fake_preds = np.random.randint(0, 2, size=(64,))\n",
        "fake_labels = np.random.randint(0, 2, size=(64,))\n",
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WkTwP_FN5Rmj"
      },
      "outputs": [],
      "source": [
        "sentence1_key, sentence2_key = (\"sentence\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C0hcmp9IrJQ"
      },
      "source": [
        "We need to take the text input and run it through the tokenizer to get input_ids, following (https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb).  We construct a properly formatted input for the Trainer class using the pre-process function defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fbfd77f1326e493ab9d20f824796bfb4",
            "0b9fc280b5dc49f4a20be579fb8a4557",
            "f6040f17f3c346828b6b48d730772806",
            "ce860d91f1484aacba15c4e14ef18062",
            "8a0d9ba5308844daa7781acdca6c343c",
            "1e246110ae8445df9ffb2882ae9116f1",
            "b73f7ca2100543cbbaa0dcfaf9f600d8",
            "e444d9fa96ca46999f8b316c69693905",
            "d3811341fd18449baa329843d07dc630",
            "86d5bbba8271462cb263afbfab2cf4f7",
            "f40069a25b4a47bb8a9f0c56a8069d1a"
          ]
        },
        "id": "DDtsaJeVIrJT",
        "outputId": "f7040bec-b333-411b-b0d3-50cbbd0073b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbfd77f1326e493ab9d20f824796bfb4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "encoded_dataset = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaPKCdr2sQJp"
      },
      "source": [
        "Lastly, we define for the future analysis the base model, the metric, and the key for the validation data in the encoded dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rF0LK6xPV85P"
      },
      "outputs": [],
      "source": [
        "metric_name = \"accuracy\"\n",
        "\n",
        "validation_key = \"validation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4poBhZZIEMy7"
      },
      "source": [
        "##2. QLoRA Setup\n",
        "\n",
        "Now let's use QLoRA to fine-tune a model that is quantized down to a much smaller bit representation. We first need to specify the BitsAndBytes configuration, then the LoRA adapter, and then we'll train as always. But now we will use the [large model](https://huggingface.co/openai-community/gpt2-large) with 812 million parameters. That would **not** fit into our T4 chip for training purposes. It will work with QLoRA! How good will the results be?  Let find out.\n",
        "\n",
        "First, your need to fill in the values of the BitsAndBytesConfig."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UDmx1SUaTdjT"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    ### YOUR CODE HERE\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    ### END YOUR CODE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DVIY9Ib-GV7"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.c. What is our quantization goal - 16 bit, 8 bit or 4 bit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNmPIm96-GV8"
      },
      "outputs": [],
      "source": [
        "### Q1-c Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "4 bit\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc4Dz38t2RMw"
      },
      "source": [
        "Let's take advantage of Hugging Face's AutoModel classes.  We're doing classification so we're going to want the AutoModelForSequenceClassification class. They've already attached an output layer for us so we simply need to load the model weights and we can fine tune our classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "cc5e3ff595ac4740b8e9985e58847438",
            "a356ee6634b64648ac19d6ba19272430",
            "5c7a0899b5c94f1f81b5767303bb8cdf",
            "745fd020a6384515a951b6296428cc19",
            "fd79c945c03a44378571bbbad8fe2dc4",
            "593e73d3a0c44b2eb62a27c1dc9895f7",
            "3bc255ed864c47a6a761271d7771992d",
            "c5c39d0c16df4122ac540b1fb778a4b8",
            "62be7c5051ec4471862eb6096c730c8d",
            "f3b4dce61d1c4df6ad116dab89c7ec10",
            "a7e45da7c92e4a779362151a27d32a97"
          ]
        },
        "id": "a8Y6wLYpTdmb",
        "outputId": "da1b1364-9c9f-41a8-a12d-6858c50cdd38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc5e3ff595ac4740b8e9985e58847438"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "qlora_model = AutoModelForSequenceClassification.from_pretrained(base_model_name, quantization_config=bnb_config, device_map={\"\":0})\n",
        "\n",
        "qlora_model.config.pad_token_id = qlora_model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgfyKAqV25e1"
      },
      "source": [
        "We can see the components of the model below. It tells us how the underlying decoder is structured.  You can see linear layer they've attached.  I generates two outputs -- one will be for positive e.g. 1 in the label and a second for negative e.g. 0 in the label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwWXf1DjOdqf",
        "outputId": "ede30ec6-e21d-4e23-fb33-34c400ba3f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2ForSequenceClassification(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 1280)\n",
            "    (wpe): Embedding(1024, 1280)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-35): 36 x GPT2Block(\n",
            "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
            "          (c_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
            "          (c_proj): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (score): Linear(in_features=1280, out_features=2, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(qlora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtPa3Iu4-36y"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.d. What kind of activation function is used in the MLP portion of the model?  RELU, LRELU, SPELU, or GELU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-ZHowa1-360"
      },
      "outputs": [],
      "source": [
        "### Q1-d Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "GELU\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKaHrx963YgG"
      },
      "source": [
        "Looking at the contents of model.config can also be very helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBGyArCQOI4G",
        "outputId": "f49f5ccf-acc6-48c6-c081-61dd6e4e0a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1280,\n",
            "  \"n_head\": 20,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 36,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(qlora_model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQM8NpPV9O_C"
      },
      "source": [
        "Now let's see how much of the GPU memory is consumed by the model BEFORE we add in the adapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgvXAb3sVwq2",
        "outputId": "ad317ea2-c9e7-4012-b429-3eaf093ac1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory allocation (GB): 0.5256361961364746\n"
          ]
        }
      ],
      "source": [
        "show_currently_allocated_gpu_mem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo9f5L-mEqvk"
      },
      "source": [
        "We need to do a few more adjustments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vmRFl_AIUY2u"
      },
      "outputs": [],
      "source": [
        "qlora_model.gradient_checkpointing_enable()\n",
        "qlora_model = prepare_model_for_kbit_training(qlora_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VVPg7ac9pLW"
      },
      "source": [
        "Now, very importantly, we need to set the size of our adapter.  Specifically we need to set the value of the rank and the alpha.  You can read about the purpose of these values in [this excellent blog](https://www.determined.ai/blog/lora-parameters) about fine-tuning with LoRA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhb5E5hCUY7K",
        "outputId": "dca6656f-abb3-4eb1-8171-bee46f1b4dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,477,120 || all params: 775,509,760 || trainable%: 0.1905\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "qlora_model = get_peft_model(qlora_model, config)\n",
        "qlora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ytRWVG1MpoJ",
        "outputId": "bcd77eb2-f619-4a07-cb4f-8f6837d4aded"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1593,  0.4168]], device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "qlora_model(**tokenizer('this is fun', return_tensors='pt').to('cuda'))['logits']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KlRLbCf-4pi"
      },
      "source": [
        "Now, let's see how much memory the LoRA adapter is using.  By looking at the difference between the GPU memory allocation before and after we can see how much space the adapter is using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z_UCrx9OmIN",
        "outputId": "94eae7b8-65ee-4a87-b3f2-4873a71535c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory allocation (GB): 0.6746611595153809\n"
          ]
        }
      ],
      "source": [
        "show_currently_allocated_gpu_mem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puOt3vUy_aQW"
      },
      "source": [
        "Now we need to configure the Hugging Face Trainer.  This involves filling out the Training Arguments structure so we can pass it on the to Trainer class when we instntiate it.  As indicated in the blog you need to find a good learning rate that will allow you to get an evaluation accuracy above 0.92.  You can experiment with multiple values.  Once you find a good one you can shift to finding good r and alpha values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF6g9YXUX350",
        "outputId": "d281bd5a-260e-40b9-f9a1-d8e558655962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-27-3759904012.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  qlora_trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "## Training Arguments structure\n",
        "args = TrainingArguments(\n",
        "    f\"qlora_{base_model_name}-finetuned-{task}\",\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 100,\n",
        "    save_strategy = \"no\",\n",
        "    logging_strategy = \"steps\",\n",
        "    logging_steps = 100,\n",
        "    learning_rate=2e-4,                   ### YOUR EXPERIMENT VALUE HERE!\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    max_steps=300,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=metric_name,\n",
        ")\n",
        "\n",
        "\n",
        "## Trainer we'll use to fine tune\n",
        "qlora_trainer = Trainer(\n",
        "    qlora_model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRFnY9ML577Z"
      },
      "source": [
        "Now that we have configured the trainer we can easily train the model by simply calling trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ftTHATekX38l",
        "outputId": "10bb3cf4-9333-4550-a0e4-d180315bd295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 05:19, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.316900</td>\n",
              "      <td>0.267376</td>\n",
              "      <td>0.916284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.244300</td>\n",
              "      <td>0.263363</td>\n",
              "      <td>0.920872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.255342</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=300, training_loss=0.26345001856486, metrics={'train_runtime': 319.8175, 'train_samples_per_second': 15.009, 'train_steps_per_second': 0.938, 'total_flos': 684337472962560.0, 'train_loss': 0.26345001856486, 'epoch': 0.07125890736342043})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "qlora_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGpciEd6SXI"
      },
      "source": [
        "Let's evaluate the trainer against our validation test set and see how well our model is performing.  The trainer class simplifies the evaluation process as well.  Your goal is to get an 'eval_accuracy' above 0.92 by manipulating the values for r, lora alpha, and the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "-WKJMD1-r2E0",
        "outputId": "ca836504-e4e9-40c5-b8bc-cf035a40470a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2553415596485138,\n",
              " 'eval_accuracy': 0.9243119266055045,\n",
              " 'eval_runtime': 19.6433,\n",
              " 'eval_samples_per_second': 44.392,\n",
              " 'eval_steps_per_second': 2.8,\n",
              " 'epoch': 0.07125890736342043}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "qlora_trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = qlora_model.peft_config[\"default\"]\n",
        "print(lora_config.r)\n",
        "print(lora_config.lora_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUeuPqtRcmxD",
        "outputId": "b117aa5e-1c05-4e17-9a9a-fc19803d7b74"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbUldNZ65Kbj"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.e. What is the value of the learning rate that allows you to get an evaluation accuracy above 0.92?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZtOuWn4EhZY"
      },
      "outputs": [],
      "source": [
        "### Q1-e Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "2e-4\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Daz6twyaBQUX"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.f. What is the r value of your LoRA adapter that lets you get an evaluation accuracy above 0.92?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBXzu2dBBQUX",
        "outputId": "e5bf406a-c185-4f7d-ef59-f60a83bb815f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "### Q1-f Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "8\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouLhzZ2OBRC3"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.g. What is the r-alpha value of your LoRA adapter that lets you get an evaluation accuracy above 0.92?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3pwtMiTBRC4"
      },
      "outputs": [],
      "source": [
        "### Q1-g Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "16\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVvN7sTwGoN8"
      },
      "source": [
        "Be very careful using this as it will clean out memory.  Only use it once you've identified the values you're happy with in fine-tuning GPT2 and you're ready to move on to the next model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HYrDR14LRjtB"
      },
      "outputs": [],
      "source": [
        "del qlora_trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eID9zRT5EiFg"
      },
      "source": [
        "## 3. Larger Model Data Setup\n",
        "\n",
        "Now let's try running the same data through a more recent model, specifically Gemma2 from Google.  You can check out [the model card](https://huggingface.co/google/gemma-2-2b) -- always a good idea or the [Technical Report](https://arxiv.org/pdf/2408.00118). We again need to define the tokenizer for our second model so we can reprocess the data.\n",
        "\n",
        "In order to use this model you will need to identify yourself to HuggingFace. If you don't already have an account with Hugging Face, you should get one.  You can then log in to the Hugging Face site and from there go to [the model card](https://huggingface.co/google/gemma-2-2b) and request access to the Gemma model.  Once you are granted access -- usually a matter of minutes -- you will see something like the following when you visit the model card:\n",
        "\n",
        "![Screenshot 2025-02-13 at 15.30.42.gif](data:image/gif;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "x9EQf34kEiFh"
      },
      "outputs": [],
      "source": [
        "task = actual_task = \"sst2\"\n",
        "large_model_name = \"google/gemma-2-2b\"\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Qo1fp1mtEiFh"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(large_model_name, use_fast=True,)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XymN5atjEiFi"
      },
      "source": [
        "We're using a new model and it has its own tokenizer so we need to reprocess the data with that new tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "acc8551c9866427e93df6bfaf336a5b6",
            "4550be67951d469389cc64f899e43518",
            "2350691d908c48c79ed9147e8462473b",
            "a615b2c2284041f0bbbbf6b2dee3f2d8",
            "a0b30711b34944a7b7f09a326b59cef0",
            "f8ac2244c58c4f44b33c08721e787bf2",
            "1dbea6a9c88f40c2a1afcdca14111df8",
            "1904f8e7410d4bc5a7c3a1d4b70a6a51",
            "23c5752e04eb4f41ba7588b3b8d7782f",
            "2a10fd26349345ecb2e75c0920ac7cfc",
            "c26758ab4f6f49208bad22e7ddaafd86",
            "d4a40a9609e8437bb819ad8296c4d31d",
            "62fcf4f7eade43e1863e785a430960fe",
            "a53018eba4ee417bb1fe8a3a558b2295",
            "320ba33ca4f64d29a17b2e7149f627d7",
            "0b86c2098e3b4d27a26014f8c9fb6cf6",
            "1b585499438a4adebbe22c7600a20e9a",
            "85d6de06ead64fe4867505f165f6bdcc",
            "7eb58f49dec2439bba5aac659f53ae1f",
            "fb746e1906c5412096d67bc645eb4397",
            "19ddac052ffd40b4b9d19b69a4baaaad",
            "087d2f4b654340f8bfe73a63f4351039",
            "4a4d26df3e7f4ccbada16de45c2f2a14",
            "725dc5f27be5437e84f6490a5349c1eb",
            "c1cbfbfb8afb4f7face03ad26b37bb04",
            "6fedc87a827244198dbf84c51088bbb7",
            "935a473f4e0849bfb6cb7c19e5a25950",
            "bc572fea77224e2080b41ea645ed3bef",
            "04d056f205a4488ab0f2fa838b8020c9",
            "cd6d5d4db5a24ec68b52e42dbe468b45",
            "adaa297da5f34dec9e5be006903442f1",
            "be300c48c13f49f491135fd47cc2f0f5",
            "44dd42fdce824893a90b2b08bb2b4d8d"
          ]
        },
        "id": "dlbmKEo0EiFi",
        "outputId": "95e4c994-3363-4a6d-d05f-9eec78118ca8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acc8551c9866427e93df6bfaf336a5b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4a40a9609e8437bb819ad8296c4d31d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a4d26df3e7f4ccbada16de45c2f2a14"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "encoded_dataset = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmYXrj5iEiFi"
      },
      "source": [
        "Lastly, we define for the future analysis the metric and the key for the validation data in the encoded dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9reHFregEiFi"
      },
      "outputs": [],
      "source": [
        "metric_name = \"accuracy\"\n",
        "\n",
        "validation_key = \"validation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seqLS3m-EiFi"
      },
      "source": [
        "##4. Larger QLoRA Setup\n",
        "\n",
        "Now let's use QLoRA to fine-tune a model that is quantized down to a much smaller number of bits. We first need to specify the BitsAndBytes configuration, then the LoRA adapter, and then we'll train. But now we will use a very recent LLM [and larger model](https://huggingface.co/google/gemma-2-2b) with 2.61 billion parameters. That would **not** fit into our T4 chip for training purposes. It will work with QLoRA. And how good it be relative to the GPT2 model we fine-tuned first?\n",
        "\n",
        "First you need to fill in the BitsAndBytesConfig file again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gDBz4PZNEiFj"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    ### YOUR CODE HERE\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        "    ### END YOUR CODE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeOCe6HvEiFj"
      },
      "source": [
        "Let's take advantage of Hugging Face's AutoModel classes.  We're doing classification so again we'll use the AutoModelForSequenceClassification. They've already attached an output layer for us so we simply need to load the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "0a5f5e13144c48b59eacff6cae20feee",
            "5da58603abee434aad5007d1c4299d1a",
            "0cd1382cf15541268a953142ad8e9880",
            "a53b5b435fb14ea6b30370f96d3f036e",
            "753f9ad1ab364ffca3ac7cd3e72ac4d8",
            "a4b4b72f69e14fe3be79364b7fbc087a",
            "2549214e82e54611bf83edd7ac5b8b81",
            "cdf331c329954098af3582a5623bf51d",
            "5e27db8013c0441a97d460979dd031a6",
            "9b46aa03c35841b799c1b5f190f0a188",
            "afdf673204d14a6c900884cb58e3faef"
          ]
        },
        "id": "-4U2i7iNEiFj",
        "outputId": "a7f25fc3-148f-471b-96ac-7b0f015feaf2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a5f5e13144c48b59eacff6cae20feee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "lqlora_model = AutoModelForSequenceClassification.from_pretrained(large_model_name, quantization_config=bnb_config, device_map={\"\":0})\n",
        "\n",
        "lqlora_model.config.pad_token_id = lqlora_model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1454vg7FEiFj"
      },
      "source": [
        "We can see the components of the model below. It tells us how the underlying decoder is structured.  You can see"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9IgF8B5EiFj",
        "outputId": "c05237a0-dcd2-4895-f70e-e7d0edfbf0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma2ForSequenceClassification(\n",
            "  (model): Gemma2Model(\n",
            "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-25): 26 x Gemma2DecoderLayer(\n",
            "        (self_attn): Gemma2Attention(\n",
            "          (q_proj): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
            "        )\n",
            "        (mlp): Gemma2MLP(\n",
            "          (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
            "          (act_fn): PytorchGELUTanh()\n",
            "        )\n",
            "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
            "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
            "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
            "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
            "    (rotary_emb): Gemma2RotaryEmbedding()\n",
            "  )\n",
            "  (score): Linear(in_features=2304, out_features=2, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(lqlora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi_gc4FFEiFj"
      },
      "source": [
        "Looking t the contents of model.config can also be very helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypjhtj_0EiFj",
        "outputId": "69bbf782-8054-471c-ae63-94c8f0e7d2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma2Config {\n",
            "  \"architectures\": [\n",
            "    \"Gemma2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attn_logit_softcapping\": 50.0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"cache_implementation\": \"hybrid\",\n",
            "  \"eos_token_id\": 1,\n",
            "  \"final_logit_softcapping\": 30.0,\n",
            "  \"head_dim\": 256,\n",
            "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
            "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
            "  \"hidden_size\": 2304,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 9216,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"gemma2\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 26,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"query_pre_attn_scalar\": 256,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 256000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(lqlora_model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpD0CKS7Np67"
      },
      "source": [
        "Now that we've loaded the Gemma model into memory let's see what size footprint it has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFv_aA2REiFj",
        "outputId": "4161d854-8dfb-4e9e-d0c6-d8021bf174ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory allocation (GB): 2.7655882835388184\n"
          ]
        }
      ],
      "source": [
        "show_currently_allocated_gpu_mem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAROPH0yEiFj"
      },
      "source": [
        "We need to do a few more adjustments to take advantge of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ugkDwNnbEiFj"
      },
      "outputs": [],
      "source": [
        "lqlora_model.gradient_checkpointing_enable()\n",
        "lqlora_model = prepare_model_for_kbit_training(lqlora_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRq9OGIaGA3M"
      },
      "source": [
        "Now you can experiment a bit with the values for r, lora_alpha, and the learning rate.  For staters try using the values you landed upon when you were fine-tuning GPT2-large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MLYGyYcEiFj",
        "outputId": "86c9e52b-c316-4465-9b1f-ff7dd2d553ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,199,488 || all params: 2,617,545,984 || trainable%: 0.1222\n"
          ]
        }
      ],
      "source": [
        "lconfig = LoraConfig(\n",
        "    r=16,               ###### YOUR VALUE HERE\n",
        "    lora_alpha=32,      ###### YOUR VALUE HERE\n",
        "    lora_dropout=0.05,  ###### YOUR VALUE HERE\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "lqlora_model = get_peft_model(lqlora_model, lconfig)\n",
        "lqlora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNkJ4CFyCysH"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.h. What is the r value of your LoRA adapter that lets you get an evaluation accuracy above 0.95?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXUDVhFrCysI"
      },
      "outputs": [],
      "source": [
        "### Q1-h Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "16\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZV1ngN-CzGV"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.i. What is the r-alpha value of your LoRA adapter that lets you get an evaluation accuracy above 0.95?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS_ccCqdCzGV"
      },
      "outputs": [],
      "source": [
        "### Q1-i Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "32\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUEbmVpdEiFj",
        "outputId": "e9e233ff-8df1-46e9-89b5-dc8de1d75952"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2362, -3.2353]], device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#qlora_model.to('cuda')\n",
        "lqlora_model(**tokenizer('this is fun', return_tensors='pt').to('cuda'))['logits']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiYQftEiCPf6"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.j. What is the number of trainable parameters in the QLoRA model for Gemma-2-2B?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eki9LufzCPf7"
      },
      "outputs": [],
      "source": [
        "### Q1-j Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "3,199,488\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llW_napkEiFk",
        "outputId": "89a6ebed-ad23-444b-c360-a3dd72279332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory allocation (GB): 3.898212432861328\n"
          ]
        }
      ],
      "source": [
        "show_currently_allocated_gpu_mem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uar0n0m6EiFk",
        "outputId": "7016453d-709b-4105-9c91-3db0c6463e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-44-265334330.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  lqlora_trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "largs = TrainingArguments(\n",
        "    f\"lqlora_{large_model_name}-finetuned-{task}\",\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 100,\n",
        "    save_strategy = \"no\",\n",
        "    logging_strategy = \"steps\",\n",
        "    logging_steps = 100,\n",
        "    learning_rate=2e-4,                ####### YOUR VALUE HERE\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    max_steps=300,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=metric_name,\n",
        "    #push_to_hub=True,\n",
        ")\n",
        "\n",
        "lqlora_trainer = Trainer(\n",
        "    lqlora_model,\n",
        "    largs,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6x3Zz_ZC8s7"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.k. What is the learning rate you are using for the larger QLoRA model to get a validation accuracy above 0.95?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onb43GzlC8s8"
      },
      "outputs": [],
      "source": [
        "### Q1-k Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "2e-4\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjvGdBOMEiFk"
      },
      "source": [
        "Now that we have configured the trainer we can easily train the model by simply calling trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "iM9PP6DlEiFk",
        "outputId": "29d76225-025a-40be-fadf-3db232ea952d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 12:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.480400</td>\n",
              "      <td>0.271093</td>\n",
              "      <td>0.910550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.220400</td>\n",
              "      <td>0.179861</td>\n",
              "      <td>0.956422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.195900</td>\n",
              "      <td>0.178255</td>\n",
              "      <td>0.954128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=300, training_loss=0.2989307657877604, metrics={'train_runtime': 778.2368, 'train_samples_per_second': 6.168, 'train_steps_per_second': 0.385, 'total_flos': 1941746571878400.0, 'train_loss': 0.2989307657877604, 'epoch': 0.07125890736342043})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "lqlora_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m34AWR-EiFk"
      },
      "source": [
        "Let's evaluate the trainer against our validation test set and see how well our model is performing.  The trainer class simplifies the evaluation process as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "zORSJCfNEiFk",
        "outputId": "05bb20c6-ede0-4f55-df60-0658a923fa13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.17825466394424438,\n",
              " 'eval_accuracy': 0.9541284403669725,\n",
              " 'eval_runtime': 47.8246,\n",
              " 'eval_samples_per_second': 18.233,\n",
              " 'eval_steps_per_second': 1.15,\n",
              " 'epoch': 0.07125890736342043}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "lqlora_trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IIG7pVZDsER"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.l. What is the final evaluation accuracy you get on the larger model?\n",
        " (Must be above 0.95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4RoQchBDsES"
      },
      "outputs": [],
      "source": [
        "### Q1-l Grading Tag: Please put your answer in this cell. Don't edit this line.\n",
        "\n",
        "### YOUR ANSWER HERE\n",
        "0.9541284403669725\n",
        "### END YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5h4L-lAO_Ti"
      },
      "source": [
        "Okay, youre done with assignment III.  Hopefully you've had a gentle introduction to using quantization and LoRA to fine tune different decoder based models."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1e7yel_pQ8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbfd77f1326e493ab9d20f824796bfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b9fc280b5dc49f4a20be579fb8a4557",
              "IPY_MODEL_f6040f17f3c346828b6b48d730772806",
              "IPY_MODEL_ce860d91f1484aacba15c4e14ef18062"
            ],
            "layout": "IPY_MODEL_8a0d9ba5308844daa7781acdca6c343c"
          }
        },
        "0b9fc280b5dc49f4a20be579fb8a4557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e246110ae8445df9ffb2882ae9116f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b73f7ca2100543cbbaa0dcfaf9f600d8",
            "value": "Map: 100%"
          }
        },
        "f6040f17f3c346828b6b48d730772806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e444d9fa96ca46999f8b316c69693905",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3811341fd18449baa329843d07dc630",
            "value": 872
          }
        },
        "ce860d91f1484aacba15c4e14ef18062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d5bbba8271462cb263afbfab2cf4f7",
            "placeholder": "​",
            "style": "IPY_MODEL_f40069a25b4a47bb8a9f0c56a8069d1a",
            "value": " 872/872 [00:00&lt;00:00, 2875.38 examples/s]"
          }
        },
        "8a0d9ba5308844daa7781acdca6c343c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e246110ae8445df9ffb2882ae9116f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73f7ca2100543cbbaa0dcfaf9f600d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e444d9fa96ca46999f8b316c69693905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3811341fd18449baa329843d07dc630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d5bbba8271462cb263afbfab2cf4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40069a25b4a47bb8a9f0c56a8069d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc5e3ff595ac4740b8e9985e58847438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a356ee6634b64648ac19d6ba19272430",
              "IPY_MODEL_5c7a0899b5c94f1f81b5767303bb8cdf",
              "IPY_MODEL_745fd020a6384515a951b6296428cc19"
            ],
            "layout": "IPY_MODEL_fd79c945c03a44378571bbbad8fe2dc4"
          }
        },
        "a356ee6634b64648ac19d6ba19272430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593e73d3a0c44b2eb62a27c1dc9895f7",
            "placeholder": "​",
            "style": "IPY_MODEL_3bc255ed864c47a6a761271d7771992d",
            "value": "model.safetensors: 100%"
          }
        },
        "5c7a0899b5c94f1f81b5767303bb8cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c39d0c16df4122ac540b1fb778a4b8",
            "max": 3247159078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62be7c5051ec4471862eb6096c730c8d",
            "value": 3247159078
          }
        },
        "745fd020a6384515a951b6296428cc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b4dce61d1c4df6ad116dab89c7ec10",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e45da7c92e4a779362151a27d32a97",
            "value": " 3.25G/3.25G [00:55&lt;00:00, 74.6MB/s]"
          }
        },
        "fd79c945c03a44378571bbbad8fe2dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593e73d3a0c44b2eb62a27c1dc9895f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc255ed864c47a6a761271d7771992d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c39d0c16df4122ac540b1fb778a4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62be7c5051ec4471862eb6096c730c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3b4dce61d1c4df6ad116dab89c7ec10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e45da7c92e4a779362151a27d32a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc8551c9866427e93df6bfaf336a5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4550be67951d469389cc64f899e43518",
              "IPY_MODEL_2350691d908c48c79ed9147e8462473b",
              "IPY_MODEL_a615b2c2284041f0bbbbf6b2dee3f2d8"
            ],
            "layout": "IPY_MODEL_a0b30711b34944a7b7f09a326b59cef0"
          }
        },
        "4550be67951d469389cc64f899e43518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ac2244c58c4f44b33c08721e787bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_1dbea6a9c88f40c2a1afcdca14111df8",
            "value": "Map: 100%"
          }
        },
        "2350691d908c48c79ed9147e8462473b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1904f8e7410d4bc5a7c3a1d4b70a6a51",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23c5752e04eb4f41ba7588b3b8d7782f",
            "value": 67349
          }
        },
        "a615b2c2284041f0bbbbf6b2dee3f2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a10fd26349345ecb2e75c0920ac7cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_c26758ab4f6f49208bad22e7ddaafd86",
            "value": " 67349/67349 [00:04&lt;00:00, 17062.30 examples/s]"
          }
        },
        "a0b30711b34944a7b7f09a326b59cef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ac2244c58c4f44b33c08721e787bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbea6a9c88f40c2a1afcdca14111df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1904f8e7410d4bc5a7c3a1d4b70a6a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c5752e04eb4f41ba7588b3b8d7782f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a10fd26349345ecb2e75c0920ac7cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26758ab4f6f49208bad22e7ddaafd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a40a9609e8437bb819ad8296c4d31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62fcf4f7eade43e1863e785a430960fe",
              "IPY_MODEL_a53018eba4ee417bb1fe8a3a558b2295",
              "IPY_MODEL_320ba33ca4f64d29a17b2e7149f627d7"
            ],
            "layout": "IPY_MODEL_0b86c2098e3b4d27a26014f8c9fb6cf6"
          }
        },
        "62fcf4f7eade43e1863e785a430960fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b585499438a4adebbe22c7600a20e9a",
            "placeholder": "​",
            "style": "IPY_MODEL_85d6de06ead64fe4867505f165f6bdcc",
            "value": "Map: 100%"
          }
        },
        "a53018eba4ee417bb1fe8a3a558b2295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb58f49dec2439bba5aac659f53ae1f",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb746e1906c5412096d67bc645eb4397",
            "value": 872
          }
        },
        "320ba33ca4f64d29a17b2e7149f627d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ddac052ffd40b4b9d19b69a4baaaad",
            "placeholder": "​",
            "style": "IPY_MODEL_087d2f4b654340f8bfe73a63f4351039",
            "value": " 872/872 [00:00&lt;00:00, 9047.72 examples/s]"
          }
        },
        "0b86c2098e3b4d27a26014f8c9fb6cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b585499438a4adebbe22c7600a20e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d6de06ead64fe4867505f165f6bdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb58f49dec2439bba5aac659f53ae1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb746e1906c5412096d67bc645eb4397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19ddac052ffd40b4b9d19b69a4baaaad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087d2f4b654340f8bfe73a63f4351039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4d26df3e7f4ccbada16de45c2f2a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725dc5f27be5437e84f6490a5349c1eb",
              "IPY_MODEL_c1cbfbfb8afb4f7face03ad26b37bb04",
              "IPY_MODEL_6fedc87a827244198dbf84c51088bbb7"
            ],
            "layout": "IPY_MODEL_935a473f4e0849bfb6cb7c19e5a25950"
          }
        },
        "725dc5f27be5437e84f6490a5349c1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc572fea77224e2080b41ea645ed3bef",
            "placeholder": "​",
            "style": "IPY_MODEL_04d056f205a4488ab0f2fa838b8020c9",
            "value": "Map: 100%"
          }
        },
        "c1cbfbfb8afb4f7face03ad26b37bb04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6d5d4db5a24ec68b52e42dbe468b45",
            "max": 1821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adaa297da5f34dec9e5be006903442f1",
            "value": 1821
          }
        },
        "6fedc87a827244198dbf84c51088bbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be300c48c13f49f491135fd47cc2f0f5",
            "placeholder": "​",
            "style": "IPY_MODEL_44dd42fdce824893a90b2b08bb2b4d8d",
            "value": " 1821/1821 [00:00&lt;00:00, 11966.21 examples/s]"
          }
        },
        "935a473f4e0849bfb6cb7c19e5a25950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc572fea77224e2080b41ea645ed3bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d056f205a4488ab0f2fa838b8020c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6d5d4db5a24ec68b52e42dbe468b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adaa297da5f34dec9e5be006903442f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be300c48c13f49f491135fd47cc2f0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44dd42fdce824893a90b2b08bb2b4d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a5f5e13144c48b59eacff6cae20feee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5da58603abee434aad5007d1c4299d1a",
              "IPY_MODEL_0cd1382cf15541268a953142ad8e9880",
              "IPY_MODEL_a53b5b435fb14ea6b30370f96d3f036e"
            ],
            "layout": "IPY_MODEL_753f9ad1ab364ffca3ac7cd3e72ac4d8"
          }
        },
        "5da58603abee434aad5007d1c4299d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b4b72f69e14fe3be79364b7fbc087a",
            "placeholder": "​",
            "style": "IPY_MODEL_2549214e82e54611bf83edd7ac5b8b81",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0cd1382cf15541268a953142ad8e9880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf331c329954098af3582a5623bf51d",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e27db8013c0441a97d460979dd031a6",
            "value": 3
          }
        },
        "a53b5b435fb14ea6b30370f96d3f036e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b46aa03c35841b799c1b5f190f0a188",
            "placeholder": "​",
            "style": "IPY_MODEL_afdf673204d14a6c900884cb58e3faef",
            "value": " 3/3 [00:58&lt;00:00, 16.39s/it]"
          }
        },
        "753f9ad1ab364ffca3ac7cd3e72ac4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b4b72f69e14fe3be79364b7fbc087a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2549214e82e54611bf83edd7ac5b8b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf331c329954098af3582a5623bf51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e27db8013c0441a97d460979dd031a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b46aa03c35841b799c1b5f190f0a188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdf673204d14a6c900884cb58e3faef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}